---
title: Los modelos de difusión (DDPM)
date: 2024-02-23 00:02:30 +/-1200
categories: [Explicacion]
tags: [difusion]     # TAG names should always be lowercase
math: true
image:
    path: assets/posts/2024-02-23-ddpm/reverse-diffusion.png
    alt: Modelo de difusión
---



En este primer post intentaré explicar todo lo que he aprendido investigando sobre los modelos de difusión. En principio nos centraremos en el primer artículo original, en el cual se explicaba el DDPM (Denoising Diffusion Probabilistic Model) original, y cuya cita se puede encontrar en el final de este post. Recomiendo echarle un vistazo también al paper original ya que es muy interasante, e intentar entenderlo apoyado en este blog o los otros recursos que dejo al final, ¡que probablemente sean incluso más útiles!

# Resumen inicial

Los modelos de difusión es un tipo de modelo generativo, es decir, se entrena a una red para que aprenda la distribución de unos datos, y pueda generar nuevas muestras pertenecientes a la distribución. Se basa principalmente en un cambio en el algoritmo de entrenamiento. Esto sería la explicación básica y general de lo que es un DDPM.


## Qué no es un modelo de difusión

Sin embargo, más que explicar qué es un modelo de difusión, me parece interesante comenzar definiendo lo que __NO__ es. 

Los DDPM no son:

- Una nueva arquitectura de modelo.
- Un nuevo tipo de modelo.
- Un nuevo tipo de capa neuronal.

Como he dicho justo antes, los modelos de difusión son solo un cambio en el algoritmo de entrenamiento y generación, nada más. Esto es similar a los Generative Adversarial Networks (GANs), ya que en esencia son dos modelos de red neuronales normales, pero que se modifica su algoritmo de entrenamiento para hacer uso de una función de pérdidas adversarial para ajustar sus respectivos parámetros.

# Funcionamiento general

Un modelo de difusión consiste en ir destruyendo unos datos de partida para corromper su distribución inicial, hasta convertir los datos en puro ruido, es decir, con una distribución normal con media cero y desviación 1, es decir: $\mathcal{N}(0, 1)$.

Para ir corrompiendo estos datos, se va añadiendo máscaras de ruido poco a poco durante una serie de pasos, lo cual se puede definir en forma de cadena de Markov con $T$ pasos. El punto inicial será $x_0$ que es nuestra muestra original, y $x_t$ el final de la cadena, en este punto  es cuando $x_t \sim \mathcal{N}(0, 1)$.

Para controlar que durante la cadena de Markov la distribución converja adecuadamente a $\mathcal{N}(0, 1)$, se controla la variación que se le aplica con cada máscara de ruido, y esta variación vendrá definida por un parámetro $\beta$. Este parámetro irá variando poco a poco hasta llegar a obtener $x_t \sim \mathcal{N}(0, 1)$, por lo que para cada paso de la cadena tendremos nuestro correspondiente $\beta_t$.

Se suele decir que por lo tanto $\beta_t$ está controlada por el Scheduler, el cual lo podeis imaginar como un objeto de python que defina de alguna forma una lista con la evolución de los valores de $\beta_t$ para cada $t$, y al cual le pedimos que nos de este valor utilizando ```scheduler.get_beta(t)```. Hay distintas técnicas que puede utilizar el Scheduler para definir estos valores, pero el paper original definió el Scheduler lineal.

> Tengo que añadir aquí las imágenes de como se corrompe una imagen por la cadena, y como cambia la evolución del beta
{: .prompt-danger }

Sabiendo esto, básicamente nuestro objetivo va a ser entrenar a un modelo para predecir que máscara de ruido se le añadió en el paso actual. De esta forma, si le restamos la máscara de ruido predicho, deberíamos de ser capaz de recuperar el estado de la muestra en el paso anterior. Si lo hacemos interativamente, deberíamos de ser capaz de utilizar nuestro modelo para predecir las máscaras de ruido de cada paso y poder pasar de $x_t$ a $x_0$.

> Imagen mia del bucle del modelo de la presentación
{: .prompt-danger }

# Componentes principales de los modelos de difusión

Dicho esto, para entender bien los modelos de diffusión, hay 5 elementos claves que tenemos que entender:

- El Scheduler
- El forward process $q(x_t|x_{t-1})$
- La posterior $q(x_{t-1}|x_t, x_0)$
- El bakward/reverse process $p_{\theta}(x_{t-1}|x_t)$
- La función de pérdidas

## Scheduler

Como hemos dicho anteriormente, la cantidad de ruido que vamos a añadir en cada paso de la cadena de Markov no va a ser constante. Está definido de una forma que asegure que cuando llegemos al final de la cadena obtengamos algo como $x_t \sim \mathcal{N}(0, 1)$. Para ello, no podemos añadir una cantidad constante de ruido, si no la variación de la distribución explotaría con la suma de este ruido, es por esto que tenemos que ir escalandolo en cada paso. El factor de escalado en cada paso lo controla el Scheduler con la definición de $\beta_t$.

Básicamente, al principio de cada paso, generaremos una matriz de ruido de la siguiente forma $\epsilon \sim \mathcal{N}(0, 1)$, y luego lo vamos a escalar usando $\beta_t$. Esto lo explicaré en más detalle en acontinuación, pero es importante que hasta este punto se haya comprendido qué es el Scheduler, qué es $\beta_t$, y que la escala de ruido que añadimos en cada paso no es constante.

## Forward/Diffusion process $q(x_t|x_{t-1})$

Okay, estamos diciendo que vamos a ir corrompiendo las muestras iniciales a lo largo de una cadena de Markov en la cual vamos a ir añadiendo ruido progresivamente, ¿pero cómo se hace esto?

Para eso, el paper original nos da la Fórmula \ref{eq:foward} para pasar de cualquier $t-1$ al siguiente paso de la cadena, es decir, $t$:

$$
\begin{equation}
  q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t I)
  \label{eq:foward}
\end{equation}
$$

## Posterior $q(x_{t-1}|x_t, x_0)$

## Backwards process $p_{\theta}(x_{t-1}|x_t)$

## Función de pérdidas

## ¿Por qué estamos preciendo $\orange{\epsilon_t}$?

# Algoritmos

## Entrenamiento

## Generación

# UNET: la primera arquitecura utilizada

# ¿Qué viene después?

## Improving diffusion

## CFG: Classifier-free guidance

## Añadir información condicional

## DDIM: Denosing Diffusion Implicit Models

# Fuentes recomendadas

- [Artículo original de DDPM](https://arxiv.org/pdf/2006.11239.pdf)

En Youtube teneis estos videos que me fueron cruciales para que pudiera comprenderlo todo:

Este primer video es en una maravilla, en 30 minutos te explica todos los conceptos matemáticos de la diffusion, probablemente la mejor fuente que he encontrado para entenderlo todo.

{% include embed/youtube.html id='HoKDTa5jHvg' %}


Este es una continuación del video anterior, en este implementa un modelo de difusión en Pytorch desde 0, una vez más, recomendadísimo.

{% include embed/youtube.html id='TBCRlnwJtZU' %}

- Este video también está muy bien, ya que lee el paper y te va explicando todo paso a paso.

{% include embed/youtube.html id='y7J6sSO1k50' %}


{% include comments.html %}